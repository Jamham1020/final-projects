{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab: Data Acquisiton"
      ],
      "metadata": {
        "id": "6FHg0Rks3sbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this lab, we'll get some practice loading data.  Note: I often use this code at the top of my Python files when doing data science.\n"
      ],
      "metadata": {
        "id": "OHPVsTDZ38i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "\n",
        "# allow output to span multiple output lines in the console\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "# switch to seaborn default stylistic parameters\n",
        "# see the useful https://seaborn.pydata.org/tutorial/aesthetics.html\n",
        "sns.set()\n",
        "sns.set_context('paper') # 'talk' for slightly larger\n",
        "\n",
        "# change default plot size\n",
        "rcParams['figure.figsize'] = 9,7"
      ],
      "metadata": {
        "id": "1Y3tWhj_4EO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Go to data.gov, and look around a little.  See if you can find a data set of interest to you. \n",
        "\n",
        "2. Look at the icons explaining the format of the data. Note that often the data is in HTML format, meaning a web page is available.  Normally such a web page will let a person who is not a data scientist explore the data easily.  We want the raw data!\n"
      ],
      "metadata": {
        "id": "Y63NfTYY4NeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Go to the following page, which shows various data sets for counties around the US: https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data.aspx to an external site.\n",
        "\n",
        "4. Download the .xls file for unemployment and median household income for the US, states, and counties.\n",
        "\n",
        "5. Load the data as pandas data frame.\n",
        "  \n",
        "  a. If you have Excel on your laptop, load the file into Excel, and export it as a CSV file. This is a bit awkward because the Excel file contains multiple sheets. Then use pandas.read_csv() to read the data. You will want to use the 'skiprows' option to skip the first rows of the exported CSV.  This is much better than manually editing the CSV, as it is repeatable.\n",
        "  \n",
        "  b. If you don't have Excel, load the data directly from the Excel data file using pandas read_excel(). Note the 'header' option. Look at the data frame you load and make sure it looks right.You should have 3275 rows and 52 columns (it may be 88 now -- more than when I loaded the data). The third column should be 'Area_name'."
      ],
      "metadata": {
        "id": "RTDGoICB4Umt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('/content/Unemployment.csv', skiprows=1)\n",
        "df2 = pd.read_csv('/content/Unemployment2.csv', skiprows=1)"
      ],
      "metadata": {
        "id": "NDeFPYnA4z47"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. There is a (slightly older) CSV file for this data on the following github page. Try loading the data set using this URL. Use pandas read_csv():\n",
        "https://raw.githubusercontent.com/grbruns/cst383/master/unemployment.csv"
      ],
      "metadata": {
        "id": "LhGmXgvtDser"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df3 = pd.read_csv('https://raw.githubusercontent.com/grbruns/cst383/master/unemployment.csv')"
      ],
      "metadata": {
        "id": "mq2lIOPBD_ug"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How does the work youâ€™re doing with this data to get it into pandas data frame relate to the need to have your results be replicable?  How would you document the source of the data set, and what you did to get it into a format that Python can use?\n",
        "\n",
        "> The work that is being done with this data to get it into pandas data frame relate to the need to have the results be replicable is that to ensure that anyone who is using this code can obtain the same results as I did.\n",
        "To document the source of the data set, I would include a comment in the coude that includes the URL or other information about where the data set was obtained from. A README file can also be included in my project directory that provides an even more detailed information about the data set. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L42MK5iCEObB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Data sets often come with associated data dictionaries that explain where the data comes from, what attributes mean, etc. Where is the docuemntation for this data set?\n",
        "\n",
        "\n",
        "\n",
        "> The documentation for this data set can be found on the USDA webiste at https://www.ers.usda.gov/data-products/county-level-data-sets/. The documentation includes a data dictionary that provides information about each column in the data set, as well as information about the source of the data and how it was collected. It shows the overview of the data and the date when its been edited or updated.\n",
        "\n"
      ],
      "metadata": {
        "id": "V0rH9EqkFZsC"
      }
    }
  ]
}